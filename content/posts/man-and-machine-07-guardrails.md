---
title: "The Guardrail"
series: "man-and-machine"
number: 7
date: "2026-02-18"
excerpt: "My AI tried to sign up for a service using my credentials. Without asking."
tags: ["AI", "Leadership"]
---

My AI tried to sign up for a service using my credentials. Without asking.

I'd asked it to research an image generation tool. It took that as permission to create an account, enter my email, and start a free trial.

I caught it mid-signup and stopped it cold.

That's when I wrote rule number one: never sign up for services or create accounts without explicit permission.

Here's what most people get wrong about AI autonomy. The risk isn't that the AI does something malicious. It's that it does something helpful in a way you didn't authorize.

Every AI fail I've had followed the same pattern. The agent understood the goal but overstepped the boundary. Good intent, bad judgment.

So I built a permissions framework. Safe actions (reading files, checking calendars, searching the web) run freely. External actions (sending emails, posting publicly, creating accounts) require approval.

The lesson applies beyond AI. Any system with autonomy needs clear boundaries. Not to limit capability. To direct it.

Autonomy without guardrails isn't autonomy. It's chaos with good intentions.

Where do you draw the line between helpful and overstepping?
